{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_weights, hidden_dim, vocab_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        Initializes the LSTM model.\n",
    "        \n",
    "        Parameters:\n",
    "        - embedding_weights: Pre-trained Word2Vec embeddings.\n",
    "        - hidden_dim: The number of features in the hidden state `h` of the LSTM.\n",
    "        - vocab_size: The size of the vocabulary.\n",
    "        - num_layers: Number of recurrent layers (default=1).\n",
    "        \n",
    "        The input to the model is expected to be a batch of word indices,\n",
    "        and the output is a batch of predictions for the next word.\n",
    "        \"\"\"\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Embedding layer with pre-trained weights\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(embedding_weights, freeze=True)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs and outputs hidden states\n",
    "        self.lstm = nn.LSTM(embedding_weights.shape[1], hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # The linear layer maps from hidden state space to vocabulary space\n",
    "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_word_indices):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model.\n",
    "        \n",
    "        Parameters:\n",
    "        - input_word_indices: A batch of word indices as input.\n",
    "        \n",
    "        Returns:\n",
    "        - output: The model's predictions for the next word.\n",
    "        \"\"\"\n",
    "        embeddings = self.word_embeddings(input_word_indices)\n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        output = self.linear(lstm_out)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained Word2Vec embeddings\n",
    "word2vec_path = 'models\\GoogleNews-vectors-negative300.bin.gz'  # Update this path\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "# Prepare embedding weights in the format expected by PyTorch\n",
    "vocab_size = len(word2vec_model.key_to_index)\n",
    "embedding_dim = word2vec_model.vector_size\n",
    "embedding_weights = torch.zeros(vocab_size, embedding_dim)\n",
    "\n",
    "for word, idx in word2vec_model.key_to_index.items():\n",
    "    embedding_weights[idx] = torch.tensor(word2vec_model[word])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings model\n",
    "torch.save(embedding_weights, 'word2vec_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting stoi and itos\n",
    "stoi = word2vec_model.key_to_index\n",
    "itos = word2vec_model.index_to_key\n",
    "\n",
    "# saving stoi and itos4\n",
    "import pickle\n",
    "with open('models/stoi.pkl', 'wb') as f:\n",
    "    pickle.dump(stoi, f)\n",
    "with open('models/itos.pkl', 'wb') as f:\n",
    "    pickle.dump(itos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class LyricsGenerator:\n",
    "    def __init__(self, model, vocab, device='cpu'):\n",
    "        \"\"\"\n",
    "        Initializes the LyricsGenerator.\n",
    "\n",
    "        Parameters:\n",
    "        - model: The trained LSTM model for lyrics generation.\n",
    "        - vocab: A mapping from words to indices and indices to words (vocab.stoi and vocab.itos).\n",
    "        - device: The device to run the generation on ('cpu' or 'cuda').\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.vocab = vocab\n",
    "        self.device = device\n",
    "\n",
    "    def sample_next_word(self, logits, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Samples the next word from the logits with a given temperature.\n",
    "\n",
    "        Parameters:\n",
    "        - logits: The logits output by the model.\n",
    "        - temperature: Controls the randomness of the sampling. Higher values lead to more random outputs.\n",
    "\n",
    "        Returns:\n",
    "        - index of the sampled word.\n",
    "        \"\"\"\n",
    "        probabilities = F.softmax(logits / temperature, dim=-1)\n",
    "        word_index = torch.multinomial(probabilities, 1).item()\n",
    "        return word_index\n",
    "\n",
    "    def generate(self, start_word, max_words=50, max_words_per_line=10, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Generates lyrics starting from a given word.\n",
    "\n",
    "        Parameters:\n",
    "        - start_word: The word to start generating from.\n",
    "        - max_words: The maximum number of words in the generated lyrics.\n",
    "        - max_words_per_line: The maximum number of words per line.\n",
    "        - temperature: Controls the randomness of the sampling.\n",
    "\n",
    "        Returns:\n",
    "        - A string containing the generated lyrics.\n",
    "        \"\"\"\n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "        words = [start_word]\n",
    "        current_word_index = torch.tensor([self.vocab.stoi[start_word]], device=self.device)\n",
    "\n",
    "        for _ in range(max_words - 1):\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(current_word_index.unsqueeze(0))[:, -1, :]\n",
    "                next_word_index = self.sample_next_word(logits, temperature)\n",
    "                next_word = self.vocab.itos[next_word_index]\n",
    "                words.append(next_word)\n",
    "                current_word_index = torch.tensor([next_word_index], device=self.device)\n",
    "\n",
    "                if len(words) % max_words_per_line == 0:\n",
    "                    words.append('\\n')\n",
    "\n",
    "            if words[-1] == '<eos>':  # Assuming <eos> is the end-of-sentence token\n",
    "                break\n",
    "\n",
    "        return ' '.join(words).replace(' \\n ', '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stoi and itos\n",
    "with open('models/stoi.pkl', 'rb') as f:\n",
    "    stoi = pickle.load(f)\n",
    "with open('models/itos.pkl', 'rb') as f:\n",
    "    itos = pickle.load(f)\n",
    "\n",
    "# load pre-trained Word2Vec embeddings\n",
    "embedding_weights = torch.load('models/word2vec_weights.pt')\n",
    "vocab_size, embedding_dim = embedding_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    \"\"\"\n",
    "    A mapping from words to indices and indices to words.\n",
    "    \"\"\"\n",
    "    def __init__(self, stoi, itos):\n",
    "        self.stoi = stoi\n",
    "        self.itos = itos\n",
    "    \n",
    "    def __call__(self, word):\n",
    "        if word in self.stoi:\n",
    "            return self.stoi[word]\n",
    "        else:\n",
    "            return self.stoi['<unk>']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.stoi)\n",
    "\n",
    "\n",
    "vocab = Vocabulary(stoi, itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Norway_Statoil_STL.OL profoundly_relearn_penitence KnowledgeTree_repository http://www.fnbcorporation.com Madrid_vibrant_nightlife Eeny_meeny Mizer Coniglio lights_hash_Spinning\n",
      "Inc._NYSE_TPX Fujitsu_Siemens Adm._Horatio_Nelson setting CNW_QLT Jimmey Seaman_Apprentice ROBERT_LOPEZ By_KIM_BRIGGEMAN\n",
      "Astute_readers George_Foulidis luxurious_lifestyles Fred_Kaweesi AAMI_Hobart sophisticated_cyberattacks Nuhu_Gagara Diesel_Emission Other_Monroe_abilia\n",
      "Pelonomi Ballintubber Jillie_Cooper Bon_Marche Rordam Snow_Aaron_McKie Mwebesa YMF DANS\n",
      "Commissioner_Kevin_MacCurtain Pigeon_Detectives dropped_GBU_##s Graysmith WADB Broadcom_BCM####_SoC Chashma_barrage CV_Mosby Bifoss\n",
      "Assemblyman_Morse_Arberry NVIDIA_GeForce_GPUs Mysteel_Research Paul_Sancya_FILE\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LSTM model with Word2Vec weights and corrected vocabulary size\n",
    "lstm_model = LSTMModel(embedding_weights=embedding_weights, hidden_dim=256, vocab_size=vocab_size, num_layers=1)\n",
    "lstm_model.to(device)\n",
    "\n",
    "# Instantiate the LyricsGenerator with the corrected mappings\n",
    "generator = LyricsGenerator(lstm_model, vocab, device)\n",
    "initial_word = 'the'  # Starting word for song generation\n",
    "song = generator.generate(initial_word)\n",
    "print(song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary writer will output to ./runs/ directory by default\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter('runs/lyrics_generator_experiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"num_layers\": 1,\n",
    "    \"embedding_dim\": 100,  # Assuming we know the embedding dimension\n",
    "    \"vocab_size\": len(vocab),  # Make sure this matches the actual vocab size\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"batch_size\": 64,\n",
    "    \"shuffle\": False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_model(model, train_loader, config):\n",
    "    \"\"\"\n",
    "    Trains the LSTM model on the given dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The LSTM model to train.\n",
    "    - train_loader: DataLoader for the training dataset.\n",
    "    - config: Dictionary containing configuration parameters.\n",
    "    \"\"\"\n",
    "    model.train()  # Switch model to training mode\n",
    "    optimizer = Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(config[\"device\"])\n",
    "    \n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "        for i, (input_words, target_words) in progress_bar:\n",
    "            input_words, target_words = input_words.to(config[\"device\"]), target_words.to(config[\"device\"])\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(input_words)\n",
    "            loss = criterion(output.view(-1, config[\"vocab_size\"]), target_words.view(-1))\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_description(f\"Epoch {epoch+1} Loss: {total_loss/(i+1):.4f}\")\n",
    "            \n",
    "        # Log the average loss for the epoch\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        writer.add_scalar('training_loss', avg_loss, epoch+1)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} Completed. Avg Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights\n",
    "torch.save(lstm_model.state_dict(), 'models/lstm_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing.preprocessing import strip_punctuation, strip_numeric\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# nltk.download('punkt')  # Uncomment if nltk's punkt tokenizer hasn't been downloaded yet\n",
    "\n",
    "word2vec_path = 'models/GoogleNews-vectors-negative300.bin.gz'  # Adjust path as necessary\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "bos_token = 'BOS'\n",
    "eos_token = 'EOS'\n",
    "eof_token = 'EOF'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_tokenize_lyrics(lyrics):\n",
    "    \"\"\"\n",
    "    Preprocesses and tokenizes lyrics, reduces OOV by leveraging Word2Vec's vocabulary.\n",
    "\n",
    "    Parameters:\n",
    "    lyrics (str): The raw lyrics as a single string.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the list of word indices, the list of vectors, and the OOV rate.\n",
    "    \"\"\"\n",
    "    # Preprocess lyrics\n",
    "    lyrics = lyrics.lower().replace('&', eos_token)\n",
    "    lyrics = f'{bos_token} {lyrics} {eof_token}'\n",
    "    lyrics = strip_punctuation(lyrics)\n",
    "    lyrics = strip_numeric(lyrics)\n",
    "    lyrics = re.sub(r'\\(.*?\\)|\\[.*?\\]', '', lyrics)  # Remove text inside parentheses and brackets\n",
    "    lyrics = lyrics.split()\n",
    "\n",
    "    # Tokenization and vectorization\n",
    "    word_ids = [word2vec_model.key_to_index.get(word, word2vec_model.key_to_index.get('UNK')) for word in lyrics]\n",
    "    vectors = [word2vec_model.get_vector(word, None) for word in lyrics if word in word2vec_model]\n",
    "    oov_rate = sum(1 for word in lyrics if word not in word2vec_model) / len(lyrics)\n",
    "\n",
    "    return word_ids, vectors, oov_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lyrics_to_dataset(csv_path):\n",
    "    \"\"\"\n",
    "    Parses the CSV containing lyrics into a structured dataset with minimal OOV.\n",
    "\n",
    "    Parameters:\n",
    "    csv_path (str): Path to the CSV file with lyrics.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are 'song_name artist' and values are word indices lists.\n",
    "    list: A list containing OOV rates for each song.\n",
    "    \"\"\"\n",
    "    train = pd.read_csv(csv_path)\n",
    "    train['artist'] = train['artist'].str.strip()\n",
    "    train['song'] = train['song'].str.strip()\n",
    "\n",
    "    lyrics_dict = {}\n",
    "    oov_rates = []\n",
    "\n",
    "    for i, row in tqdm(train.iterrows(), total=len(train)):\n",
    "        word_ids, vectors, oov_rate = preprocess_and_tokenize_lyrics(row['lyrics'])\n",
    "        key = f\"{row['song']} {row['artist']}\"\n",
    "        lyrics_dict[key] = word_ids\n",
    "        oov_rates.append(oov_rate)\n",
    "\n",
    "    return lyrics_dict, oov_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604831731cc8492db5582a937f207f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average OOV Rate: 6.94%\n"
     ]
    }
   ],
   "source": [
    "csv_path = 'data/lyrics_train_set2.csv'  # Update to your CSV path\n",
    "lyrics_dict, oov_rates = parse_lyrics_to_dataset(csv_path)\n",
    "\n",
    "# Analyze OOV Rates\n",
    "average_oov_rate = sum(oov_rates) / len(oov_rates)\n",
    "print(f\"Average OOV Rate: {average_oov_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lyrics dict\n",
    "import pickle\n",
    "with open('models/lyrics_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(lyrics_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, lyrics_dict):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with preprocessed lyrics.\n",
    "        \n",
    "        Parameters:\n",
    "        lyrics_dict (dict): A dictionary where keys are 'song_name artist' and values are lists of word indices.\n",
    "        \"\"\"\n",
    "        self.lyrics_indices = [indices for indices in lyrics_dict.values()]\n",
    "        self.all_indices = [idx for sublist in self.lyrics_indices for idx in sublist]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of word indices in the dataset.\"\"\"\n",
    "        return len(self.all_indices) - 1  # Subtract 1 because we use a look-ahead of 1 for targets\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns a tuple (current_word_index, next_word_index) for training.\n",
    "        \n",
    "        Parameters:\n",
    "        index (int): The index of the current word.\n",
    "        \n",
    "        Returns:\n",
    "        tuple: A tuple of tensors (current_word_index, next_word_index).\n",
    "        \"\"\"\n",
    "        return (torch.tensor(self.all_indices[index], dtype=torch.long), \n",
    "                torch.tensor(self.all_indices[index + 1], dtype=torch.long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1c2aab40490>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = LyricsDataset(lyrics_dict)\n",
    "train_loader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=config['shuffle'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89623a2a7d82448e96422e23d5fc45aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3021 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 27\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, config)\u001b[0m\n\u001b[0;32m     24\u001b[0m input_words, target_words \u001b[38;5;241m=\u001b[39m input_words\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m]), target_words\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]), target_words\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\nnenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, input_word_indices)\u001b[0m\n\u001b[0;32m     41\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings(input_word_indices)\n\u001b[0;32m     42\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(embeddings)\n\u001b[1;32m---> 43\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\nnenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\nnenv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(lstm_model, train_loader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
