{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amaruy/.conda/envs/lyricmaker/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from lyrics_generator import LyricsGenerator\n",
    "import pickle\n",
    "from models.lstm import LSTMModel\n",
    "import torch\n",
    "from gensim.models import KeyedVectors\n",
    "import random\n",
    "from sys import path\n",
    "path.append('../')\n",
    "from utils.lyrics_parser import lyrics2dict\n",
    "random.seed(563)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_metrics(text1, text2, word2vec_model):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity, and BLEU score between two texts.\n",
    "    \n",
    "    Parameters:\n",
    "    text1 (str): The first text.\n",
    "    text2 (str): The second text.\n",
    "    word2vec_model (gensim.models.KeyedVectors): Pre-trained Word2Vec model.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the cosine similarity, WMD, and BLEU score.\n",
    "    \"\"\"\n",
    "    # Tokenize and vectorize texts\n",
    "    tokens1 = text1.lower().split()\n",
    "    tokens2 = text2.lower().split()\n",
    "    \n",
    "    vectors1 = [word2vec_model[word] for word in tokens1 if word in word2vec_model]\n",
    "    vectors2 = [word2vec_model[word] for word in tokens2 if word in word2vec_model]\n",
    "    \n",
    "    # Cosine similarity\n",
    "    # Avoid division by zero and ensure valid vectors for cosine similarity calculation\n",
    "    if len(vectors1) > 0 and len(vectors2) > 0:\n",
    "        mean_vector1 = np.mean(vectors1, axis=0)\n",
    "        mean_vector2 = np.mean(vectors2, axis=0)\n",
    "        cosine_sim = 1 - cosine(mean_vector1, mean_vector2)\n",
    "    else:\n",
    "        cosine_sim = float('nan')\n",
    "    \n",
    "\n",
    "    \n",
    "    # BLEU score\n",
    "    # Note: `sentence_bleu` expects a list of reference sentences, where each reference is tokenized\n",
    "    bleu_score = sentence_bleu([tokens1], tokens2)\n",
    "    \n",
    "    return {\n",
    "        'Cosine Similarity': cosine_sim,\n",
    "        'BLEU Score': bleu_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics Generator Initialized!\n"
     ]
    }
   ],
   "source": [
    "# load midi_embeddings.pkl\n",
    "with open('../data/midi_embeddings.pkl', 'rb') as f:\n",
    "    midi_embeddings = pickle.load(f)\n",
    "\n",
    "# load word2vec model\n",
    "word2vec_model = KeyedVectors.load('../models/weights/word2vec-google-news-300.model')\n",
    "\n",
    "# Load the trained LSTM model\n",
    "input_size = word2vec_model.vector_size + len(list(midi_embeddings.values())[0][0])\n",
    "lstm_model = LSTMModel(input_dim=input_size, hidden_dim=128, vocab_size=len(word2vec_model), num_layers=2)\n",
    "lstm_model.load_state_dict(torch.load('../models/weights/lstm_int_128_2_0.001_continued_weights.pth'))\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "lyrics_generator = LyricsGenerator(lstm_model, word2vec_model, midi_embeddings, device=device)\n",
    "print(\"Lyrics Generator Initialized!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Lyrics:\n",
      " seem me may not i ve ve tried \n",
      " i ve tried \n",
      " doesn t matter it \n",
      " tell me home \n",
      " for breaking from hard \n",
      " but the get about typical \n",
      " at the both wondering i ve forgotten \n",
      " i call \n",
      " i m us \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate lyrics with a specific song key and seed text\n",
    "song_key = 'hello adele'\n",
    "seed_text = 'BOS'\n",
    "max_length = 100\n",
    "temperature = 1  # Adjust for creativity\n",
    "\n",
    "generated_lyrics = lyrics_generator.generate(song_key=song_key, seed_text=seed_text, max_length=max_length, temperature=temperature)\n",
    "print(\"Generated Lyrics:\\n\", generated_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lyrics dicts\n",
    "with open('../data/lyrics_dict.pkl', 'rb') as f:\n",
    "    lyric_dicts = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_similarity(songs, lyric_dicts, epochs=10):\n",
    "    \"\"\"\n",
    "    Test the lyrics generator on a set of songs, comparing generated lyrics against original lyrics.\n",
    "    Evaluates the similarity of generated lyrics to the original lyrics based on predefined metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - songs (list of str): A list of song keys to generate lyrics for.\n",
    "    - epochs (int, optional): The number of times to generate lyrics for each song. Defaults to 10.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame containing similarity metrics for generated lyrics across all songs and epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert word indices in lyrics to words using the Word2Vec model\n",
    "    original_lyrics = {\n",
    "        song: ' '.join([word2vec_model.index_to_key[word_index] for word_index in lyric_dicts[song]])\n",
    "        .replace('EOF', '').replace('EOS', '\\n').replace('BOS', '')\n",
    "        for song in songs\n",
    "    }\n",
    "    \n",
    "    # Generate lyrics for each song across specified epochs\n",
    "    generated_lyrics = {\n",
    "        song: [lyrics_generator.generate(song_key=song, seed_text='BOS', max_length=100, temperature=1.0) for _ in range(epochs)]\n",
    "        for song in songs\n",
    "    }\n",
    "    \n",
    "    # Calculate similarity metrics for generated lyrics against original lyrics\n",
    "    similarity_metrics = {\n",
    "        song: [calculate_similarity_metrics(original_lyrics[song], lyric, word2vec_model) for lyric in generated_lyrics[song]]\n",
    "        for song in songs\n",
    "    }\n",
    "    \n",
    "    # Flatten the similarity metrics into a DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {'song': song, **metrics}  # Assuming calculate_similarity_metrics returns a dict of metrics\n",
    "        for song, metrics_list in similarity_metrics.items()\n",
    "        for metrics in metrics_list\n",
    "    ])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 989.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOV:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load lyrics_test_set.csv\n",
    "lyrics_test_set = pd.read_csv('../data/lyrics_test_set.csv')\n",
    "\n",
    "test_dict, _, oov = lyrics2dict(lyrics_test_set)\n",
    "print(\"OOV: \", oov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined set of midi and lyric keys\n",
    "midi_keys = set(midi_embeddings.keys())\n",
    "lyric_keys = set(lyric_dicts.keys())\n",
    "test_keys = set(test_dict.keys())\n",
    "train_songs = midi_keys.intersection(lyric_keys)\n",
    "test_songs = midi_keys.intersection(test_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shoop shoop song cher',\n",
       " 'even now barry manilow',\n",
       " 'cruel summer bananarama',\n",
       " 'kim eminem',\n",
       " 'the real slim shady eminem',\n",
       " 'manic monday the bangles',\n",
       " 'zoot suit riot cherry poppin daddies',\n",
       " 'brick ben folds five',\n",
       " 'take it easy the eagles',\n",
       " 'to love you more celine dion',\n",
       " 'superstar the carpenters',\n",
       " 'rock me amadeus falco',\n",
       " 'how deep is your love bee gees',\n",
       " 'what can i say boz scaggs',\n",
       " 'son of a preacher man dusty springfield',\n",
       " 'immortality celine dion',\n",
       " 'dammit blink 182',\n",
       " 'too hot coolio',\n",
       " 'love gives love takes the corrs',\n",
       " 'land of confusion genesis',\n",
       " 'everything i own bread',\n",
       " 'wrap it up fabulous thunderbirds',\n",
       " 'attitude dancing carly simon',\n",
       " 'hungry eyes eric carmen',\n",
       " 'on the border al stewart',\n",
       " 'only time will tell asia',\n",
       " 'sweet love anita baker',\n",
       " 'at your side the corrs',\n",
       " 'from the bottom of my broken heart britney spears',\n",
       " 'dancing with myself billy idol',\n",
       " 'father of mine everclear',\n",
       " 'criminal fiona apple',\n",
       " 'you light up my life debby boone',\n",
       " 'lucky britney spears',\n",
       " 'forgiven not forgotten the corrs',\n",
       " 'just the two of us bill withers',\n",
       " 'baby i love you andy kim',\n",
       " 'rock the casbah the clash',\n",
       " 'bad girls donna summer',\n",
       " 'i swear all 4 one',\n",
       " 'under the influence eminem',\n",
       " 'all cried out allure',\n",
       " 'pretty maids all in a row the eagles',\n",
       " 'come and get it badfinger',\n",
       " 'turn your love around george benson',\n",
       " 'remember the corrs',\n",
       " 'your clown eiffel 65',\n",
       " 'everything to everyone everclear',\n",
       " 'words boyzone',\n",
       " 'from a distance bette midler']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = random.sample(list(train_songs), 50)\n",
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amaruy/.conda/envs/lyricmaker/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/amaruy/.conda/envs/lyricmaker/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/amaruy/.conda/envs/lyricmaker/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "df = test_similarity(songs, lyric_dicts=lyric_dicts, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Cosine Similarity    0.906297\n",
       " BLEU Score           0.010602\n",
       " dtype: float64,\n",
       " Cosine Similarity    0.045925\n",
       " BLEU Score           0.007836\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate average and std for each song\n",
    "df.groupby(df.song).mean().mean(), df.groupby(df.song).std().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amaruy/.conda/envs/lyricmaker/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/amaruy/.conda/envs/lyricmaker/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/amaruy/.conda/envs/lyricmaker/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# test on test\n",
    "test_df = test_similarity(test_songs, lyric_dicts=test_dict, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Cosine Similarity    8.494694e-01\n",
       " BLEU Score           4.521129e-80\n",
       " dtype: float64,\n",
       " Cosine Similarity    2.595883e-02\n",
       " BLEU Score           1.264184e-79\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate average and std for each song\n",
    "test_df.groupby(test_df.song).mean().mean(), test_df.groupby(test_df.song).std().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all the small things blink 182',\n",
       " 'barbie girl aqua',\n",
       " 'eternal flame the bangles',\n",
       " 'honesty billy joel',\n",
       " 'lovefool cardigans'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when fire \n",
      " in with my own by the skin truth \n",
      " while truth like \n",
      " should cares \n",
      " making \n",
      " bed when my own truth again again the baby \n",
      " where you \n",
      " i must t make me with my motherfuckin \n",
      " i hear you mine name inside lives with bed wine s world is i am i ll spend for catch back apart apart fighting my \n",
      " i \n",
      " door \n",
      " i do apart \n",
      " crying who truth you means \n",
      " tell the own bed my own \n",
      " crying i am again \n",
      " where the world words \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate lyrics for a song\n",
    "song = 'eternal flame the bangles'\n",
    "lyrics = lyrics_generator.generate(song_key=song, seed_text='BOS', max_length=100, temperature=1.0)\n",
    "print(lyrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
